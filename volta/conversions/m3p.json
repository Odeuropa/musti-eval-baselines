{
  "module.position_embeddings.weight": "bert.embeddings.position_embeddings.weight",
  "module.embeddings.weight": "bert.embeddings.word_embeddings.weight",
  "module.layer_norm_emb.weight": "bert.embeddings.LayerNorm.weight",
  "module.layer_norm_emb.bias": "bert.embeddings.LayerNorm.bias",
  "module.image_embeddings.image_embeddings.weight": "bert.embeddings.image_embeddings.weight",
  "module.image_embeddings.image_embeddings.bias": "bert.embeddings.image_embeddings.bias",
  "module.image_embeddings.image_location_embeddings.weight": "bert.embeddings.image_location_embeddings.weight",
  "module.image_embeddings.image_location_embeddings.bias": "bert.embeddings.image_location_embeddings.bias",
  "module.image_embeddings.LayerNorm.weight": "bert.embeddings.v_LayerNorm.weight",
  "module.image_embeddings.LayerNorm.bias": "bert.embeddings.v_LayerNorm.bias",
  "module.attentions.0.q_lin.weight": "bert.encoder.layer.0.attention_self.query.weight",
  "module.attentions.0.q_lin.bias": "bert.encoder.layer.0.attention_self.query.bias",
  "module.attentions.0.k_lin.weight": "bert.encoder.layer.0.attention_self.key.weight",
  "module.attentions.0.k_lin.bias": "bert.encoder.layer.0.attention_self.key.bias",
  "module.attentions.0.v_lin.weight": "bert.encoder.layer.0.attention_self.value.weight",
  "module.attentions.0.v_lin.bias": "bert.encoder.layer.0.attention_self.value.bias",
  "module.attentions.0.out_lin.weight": "bert.encoder.layer.0.attention_output.dense.weight",
  "module.attentions.0.out_lin.bias": "bert.encoder.layer.0.attention_output.dense.bias",
  "module.attentions.1.q_lin.weight": "bert.encoder.layer.2.attention_self.query.weight",
  "module.attentions.1.q_lin.bias": "bert.encoder.layer.2.attention_self.query.bias",
  "module.attentions.1.k_lin.weight": "bert.encoder.layer.2.attention_self.key.weight",
  "module.attentions.1.k_lin.bias": "bert.encoder.layer.2.attention_self.key.bias",
  "module.attentions.1.v_lin.weight": "bert.encoder.layer.2.attention_self.value.weight",
  "module.attentions.1.v_lin.bias": "bert.encoder.layer.2.attention_self.value.bias",
  "module.attentions.1.out_lin.weight": "bert.encoder.layer.2.attention_output.dense.weight",
  "module.attentions.1.out_lin.bias": "bert.encoder.layer.2.attention_output.dense.bias",
  "module.attentions.2.q_lin.weight": "bert.encoder.layer.4.attention_self.query.weight",
  "module.attentions.2.q_lin.bias": "bert.encoder.layer.4.attention_self.query.bias",
  "module.attentions.2.k_lin.weight": "bert.encoder.layer.4.attention_self.key.weight",
  "module.attentions.2.k_lin.bias": "bert.encoder.layer.4.attention_self.key.bias",
  "module.attentions.2.v_lin.weight": "bert.encoder.layer.4.attention_self.value.weight",
  "module.attentions.2.v_lin.bias": "bert.encoder.layer.4.attention_self.value.bias",
  "module.attentions.2.out_lin.weight": "bert.encoder.layer.4.attention_output.dense.weight",
  "module.attentions.2.out_lin.bias": "bert.encoder.layer.4.attention_output.dense.bias",
  "module.attentions.3.q_lin.weight": "bert.encoder.layer.6.attention_self.query.weight",
  "module.attentions.3.q_lin.bias": "bert.encoder.layer.6.attention_self.query.bias",
  "module.attentions.3.k_lin.weight": "bert.encoder.layer.6.attention_self.key.weight",
  "module.attentions.3.k_lin.bias": "bert.encoder.layer.6.attention_self.key.bias",
  "module.attentions.3.v_lin.weight": "bert.encoder.layer.6.attention_self.value.weight",
  "module.attentions.3.v_lin.bias": "bert.encoder.layer.6.attention_self.value.bias",
  "module.attentions.3.out_lin.weight": "bert.encoder.layer.6.attention_output.dense.weight",
  "module.attentions.3.out_lin.bias": "bert.encoder.layer.6.attention_output.dense.bias",
  "module.attentions.4.q_lin.weight": "bert.encoder.layer.8.attention_self.query.weight",
  "module.attentions.4.q_lin.bias": "bert.encoder.layer.8.attention_self.query.bias",
  "module.attentions.4.k_lin.weight": "bert.encoder.layer.8.attention_self.key.weight",
  "module.attentions.4.k_lin.bias": "bert.encoder.layer.8.attention_self.key.bias",
  "module.attentions.4.v_lin.weight": "bert.encoder.layer.8.attention_self.value.weight",
  "module.attentions.4.v_lin.bias": "bert.encoder.layer.8.attention_self.value.bias",
  "module.attentions.4.out_lin.weight": "bert.encoder.layer.8.attention_output.dense.weight",
  "module.attentions.4.out_lin.bias": "bert.encoder.layer.8.attention_output.dense.bias",
  "module.attentions.5.q_lin.weight": "bert.encoder.layer.10.attention_self.query.weight",
  "module.attentions.5.q_lin.bias": "bert.encoder.layer.10.attention_self.query.bias",
  "module.attentions.5.k_lin.weight": "bert.encoder.layer.10.attention_self.key.weight",
  "module.attentions.5.k_lin.bias": "bert.encoder.layer.10.attention_self.key.bias",
  "module.attentions.5.v_lin.weight": "bert.encoder.layer.10.attention_self.value.weight",
  "module.attentions.5.v_lin.bias": "bert.encoder.layer.10.attention_self.value.bias",
  "module.attentions.5.out_lin.weight": "bert.encoder.layer.10.attention_output.dense.weight",
  "module.attentions.5.out_lin.bias": "bert.encoder.layer.10.attention_output.dense.bias",
  "module.attentions.6.q_lin.weight": "bert.encoder.layer.12.attention_self.query.weight",
  "module.attentions.6.q_lin.bias": "bert.encoder.layer.12.attention_self.query.bias",
  "module.attentions.6.k_lin.weight": "bert.encoder.layer.12.attention_self.key.weight",
  "module.attentions.6.k_lin.bias": "bert.encoder.layer.12.attention_self.key.bias",
  "module.attentions.6.v_lin.weight": "bert.encoder.layer.12.attention_self.value.weight",
  "module.attentions.6.v_lin.bias": "bert.encoder.layer.12.attention_self.value.bias",
  "module.attentions.6.out_lin.weight": "bert.encoder.layer.12.attention_output.dense.weight",
  "module.attentions.6.out_lin.bias": "bert.encoder.layer.12.attention_output.dense.bias",
  "module.attentions.7.q_lin.weight": "bert.encoder.layer.14.attention_self.query.weight",
  "module.attentions.7.q_lin.bias": "bert.encoder.layer.14.attention_self.query.bias",
  "module.attentions.7.k_lin.weight": "bert.encoder.layer.14.attention_self.key.weight",
  "module.attentions.7.k_lin.bias": "bert.encoder.layer.14.attention_self.key.bias",
  "module.attentions.7.v_lin.weight": "bert.encoder.layer.14.attention_self.value.weight",
  "module.attentions.7.v_lin.bias": "bert.encoder.layer.14.attention_self.value.bias",
  "module.attentions.7.out_lin.weight": "bert.encoder.layer.14.attention_output.dense.weight",
  "module.attentions.7.out_lin.bias": "bert.encoder.layer.14.attention_output.dense.bias",
  "module.attentions.8.q_lin.weight": "bert.encoder.layer.16.attention_self.query.weight",
  "module.attentions.8.q_lin.bias": "bert.encoder.layer.16.attention_self.query.bias",
  "module.attentions.8.k_lin.weight": "bert.encoder.layer.16.attention_self.key.weight",
  "module.attentions.8.k_lin.bias": "bert.encoder.layer.16.attention_self.key.bias",
  "module.attentions.8.v_lin.weight": "bert.encoder.layer.16.attention_self.value.weight",
  "module.attentions.8.v_lin.bias": "bert.encoder.layer.16.attention_self.value.bias",
  "module.attentions.8.out_lin.weight": "bert.encoder.layer.16.attention_output.dense.weight",
  "module.attentions.8.out_lin.bias": "bert.encoder.layer.16.attention_output.dense.bias",
  "module.attentions.9.q_lin.weight": "bert.encoder.layer.18.attention_self.query.weight",
  "module.attentions.9.q_lin.bias": "bert.encoder.layer.18.attention_self.query.bias",
  "module.attentions.9.k_lin.weight": "bert.encoder.layer.18.attention_self.key.weight",
  "module.attentions.9.k_lin.bias": "bert.encoder.layer.18.attention_self.key.bias",
  "module.attentions.9.v_lin.weight": "bert.encoder.layer.18.attention_self.value.weight",
  "module.attentions.9.v_lin.bias": "bert.encoder.layer.18.attention_self.value.bias",
  "module.attentions.9.out_lin.weight": "bert.encoder.layer.18.attention_output.dense.weight",
  "module.attentions.9.out_lin.bias": "bert.encoder.layer.18.attention_output.dense.bias",
  "module.attentions.10.q_lin.weight": "bert.encoder.layer.20.attention_self.query.weight",
  "module.attentions.10.q_lin.bias": "bert.encoder.layer.20.attention_self.query.bias",
  "module.attentions.10.k_lin.weight": "bert.encoder.layer.20.attention_self.key.weight",
  "module.attentions.10.k_lin.bias": "bert.encoder.layer.20.attention_self.key.bias",
  "module.attentions.10.v_lin.weight": "bert.encoder.layer.20.attention_self.value.weight",
  "module.attentions.10.v_lin.bias": "bert.encoder.layer.20.attention_self.value.bias",
  "module.attentions.10.out_lin.weight": "bert.encoder.layer.20.attention_output.dense.weight",
  "module.attentions.10.out_lin.bias": "bert.encoder.layer.20.attention_output.dense.bias",
  "module.attentions.11.q_lin.weight": "bert.encoder.layer.22.attention_self.query.weight",
  "module.attentions.11.q_lin.bias": "bert.encoder.layer.22.attention_self.query.bias",
  "module.attentions.11.k_lin.weight": "bert.encoder.layer.22.attention_self.key.weight",
  "module.attentions.11.k_lin.bias": "bert.encoder.layer.22.attention_self.key.bias",
  "module.attentions.11.v_lin.weight": "bert.encoder.layer.22.attention_self.value.weight",
  "module.attentions.11.v_lin.bias": "bert.encoder.layer.22.attention_self.value.bias",
  "module.attentions.11.out_lin.weight": "bert.encoder.layer.11.attention_output.dense.weight",
  "module.attentions.11.out_lin.bias": "bert.encoder.layer.22.attention_output.dense.bias",
  "module.layer_norm1.0.weight": "bert.encoder.layer.0.attention_output.LayerNorm.weight",
  "module.layer_norm1.0.bias": "bert.encoder.layer.0.attention_output.LayerNorm.bias",
  "module.layer_norm1.1.weight": "bert.encoder.layer.2.attention_output.LayerNorm.weight",
  "module.layer_norm1.1.bias": "bert.encoder.layer.2.attention_output.LayerNorm.bias",
  "module.layer_norm1.2.weight": "bert.encoder.layer.4.attention_output.LayerNorm.weight",
  "module.layer_norm1.2.bias": "bert.encoder.layer.4.attention_output.LayerNorm.bias",
  "module.layer_norm1.3.weight": "bert.encoder.layer.6.attention_output.LayerNorm.weight",
  "module.layer_norm1.3.bias": "bert.encoder.layer.6.attention_output.LayerNorm.bias",
  "module.layer_norm1.4.weight": "bert.encoder.layer.8.attention_output.LayerNorm.weight",
  "module.layer_norm1.4.bias": "bert.encoder.layer.8.attention_output.LayerNorm.bias",
  "module.layer_norm1.5.weight": "bert.encoder.layer.10.attention_output.LayerNorm.weight",
  "module.layer_norm1.5.bias": "bert.encoder.layer.10.attention_output.LayerNorm.bias",
  "module.layer_norm1.6.weight": "bert.encoder.layer.12.attention_output.LayerNorm.weight",
  "module.layer_norm1.6.bias": "bert.encoder.layer.12.attention_output.LayerNorm.bias",
  "module.layer_norm1.7.weight": "bert.encoder.layer.14.attention_output.LayerNorm.weight",
  "module.layer_norm1.7.bias": "bert.encoder.layer.14.attention_output.LayerNorm.bias",
  "module.layer_norm1.8.weight": "bert.encoder.layer.16.attention_output.LayerNorm.weight",
  "module.layer_norm1.8.bias": "bert.encoder.layer.16.attention_output.LayerNorm.bias",
  "module.layer_norm1.9.weight": "bert.encoder.layer.18.attention_output.LayerNorm.weight",
  "module.layer_norm1.9.bias": "bert.encoder.layer.18.attention_output.LayerNorm.bias",
  "module.layer_norm1.10.weight": "bert.encoder.layer.20.attention_output.LayerNorm.weight",
  "module.layer_norm1.10.bias": "bert.encoder.layer.20.attention_output.LayerNorm.bias",
  "module.layer_norm1.11.weight": "bert.encoder.layer.22.attention_output.LayerNorm.weight",
  "module.layer_norm1.11.bias": "bert.encoder.layer.22.attention_output.LayerNorm.bias",
  "module.ffns.0.lin1.weight": "bert.encoder.layer.1.intermediate.dense.weight",
  "module.ffns.0.lin1.bias": "bert.encoder.layer.1.intermediate.dense.bias",
  "module.ffns.0.lin2.weight": "bert.encoder.layer.1.output.dense.weight",
  "module.ffns.0.lin2.bias": "bert.encoder.layer.1.output.dense.bias",
  "module.ffns.1.lin1.weight": "bert.encoder.layer.3.intermediate.dense.weight",
  "module.ffns.1.lin1.bias": "bert.encoder.layer.3.intermediate.dense.bias",
  "module.ffns.1.lin2.weight": "bert.encoder.layer.3.output.dense.weight",
  "module.ffns.1.lin2.bias": "bert.encoder.layer.3.output.dense.bias",
  "module.ffns.2.lin1.weight": "bert.encoder.layer.5.intermediate.dense.weight",
  "module.ffns.2.lin1.bias": "bert.encoder.layer.5.intermediate.dense.bias",
  "module.ffns.2.lin2.weight": "bert.encoder.layer.5.output.dense.weight",
  "module.ffns.2.lin2.bias": "bert.encoder.layer.5.output.dense.bias",
  "module.ffns.3.lin1.weight": "bert.encoder.layer.7.intermediate.dense.weight",
  "module.ffns.3.lin1.bias": "bert.encoder.layer.7.intermediate.dense.bias",
  "module.ffns.3.lin2.weight": "bert.encoder.layer.7.output.dense.weight",
  "module.ffns.3.lin2.bias": "bert.encoder.layer.7.output.dense.bias",
  "module.ffns.4.lin1.weight": "bert.encoder.layer.9.intermediate.dense.weight",
  "module.ffns.4.lin1.bias": "bert.encoder.layer.9.intermediate.dense.bias",
  "module.ffns.4.lin2.weight": "bert.encoder.layer.9.output.dense.weight",
  "module.ffns.4.lin2.bias": "bert.encoder.layer.9.output.dense.bias",
  "module.ffns.5.lin1.weight": "bert.encoder.layer.11.intermediate.dense.weight",
  "module.ffns.5.lin1.bias": "bert.encoder.layer.11.intermediate.dense.bias",
  "module.ffns.5.lin2.weight": "bert.encoder.layer.11.output.dense.weight",
  "module.ffns.5.lin2.bias": "bert.encoder.layer.11.output.dense.bias",
  "module.ffns.6.lin1.weight": "bert.encoder.layer.13.intermediate.dense.weight",
  "module.ffns.6.lin1.bias": "bert.encoder.layer.13.intermediate.dense.bias",
  "module.ffns.6.lin2.weight": "bert.encoder.layer.13.output.dense.weight",
  "module.ffns.6.lin2.bias": "bert.encoder.layer.13.output.dense.bias",
  "module.ffns.7.lin1.weight": "bert.encoder.layer.15.intermediate.dense.weight",
  "module.ffns.7.lin1.bias": "bert.encoder.layer.15.intermediate.dense.bias",
  "module.ffns.7.lin2.weight": "bert.encoder.layer.15.output.dense.weight",
  "module.ffns.7.lin2.bias": "bert.encoder.layer.15.output.dense.bias",
  "module.ffns.8.lin1.weight": "bert.encoder.layer.17.intermediate.dense.weight",
  "module.ffns.8.lin1.bias": "bert.encoder.layer.17.intermediate.dense.bias",
  "module.ffns.8.lin2.weight": "bert.encoder.layer.17.output.dense.weight",
  "module.ffns.8.lin2.bias": "bert.encoder.layer.17.output.dense.bias",
  "module.ffns.9.lin1.weight": "bert.encoder.layer.19.intermediate.dense.weight",
  "module.ffns.9.lin1.bias": "bert.encoder.layer.19.intermediate.dense.bias",
  "module.ffns.9.lin2.weight": "bert.encoder.layer.19.output.dense.weight",
  "module.ffns.9.lin2.bias": "bert.encoder.layer.19.output.dense.bias",
  "module.ffns.10.lin1.weight": "bert.encoder.layer.21.intermediate.dense.weight",
  "module.ffns.10.lin1.bias": "bert.encoder.layer.21.intermediate.dense.bias",
  "module.ffns.10.lin2.weight": "bert.encoder.layer.21.output.dense.weight",
  "module.ffns.10.lin2.bias": "bert.encoder.layer.21.output.dense.bias",
  "module.ffns.11.lin1.weight": "bert.encoder.layer.23.intermediate.dense.weight",
  "module.ffns.11.lin1.bias": "bert.encoder.layer.23.intermediate.dense.bias",
  "module.ffns.11.lin2.weight": "bert.encoder.layer.23.output.dense.weight",
  "module.ffns.11.lin2.bias": "bert.encoder.layer.23.output.dense.bias",
  "module.layer_norm2.0.weight": "bert.encoder.layer.1.output.LayerNorm.weight",
  "module.layer_norm2.0.bias": "bert.encoder.layer.1.output.LayerNorm.bias",
  "module.layer_norm2.1.weight": "bert.encoder.layer.3.output.LayerNorm.weight",
  "module.layer_norm2.1.bias": "bert.encoder.layer.3.output.LayerNorm.bias",
  "module.layer_norm2.2.weight": "bert.encoder.layer.5.output.LayerNorm.weight",
  "module.layer_norm2.2.bias": "bert.encoder.layer.5.output.LayerNorm.bias",
  "module.layer_norm2.3.weight": "bert.encoder.layer.7.output.LayerNorm.weight",
  "module.layer_norm2.3.bias": "bert.encoder.layer.7.output.LayerNorm.bias",
  "module.layer_norm2.4.weight": "bert.encoder.layer.9.output.LayerNorm.weight",
  "module.layer_norm2.4.bias": "bert.encoder.layer.9.output.LayerNorm.bias",
  "module.layer_norm2.5.weight": "bert.encoder.layer.11.output.LayerNorm.weight",
  "module.layer_norm2.5.bias": "bert.encoder.layer.11.output.LayerNorm.bias",
  "module.layer_norm2.6.weight": "bert.encoder.layer.13.output.LayerNorm.weight",
  "module.layer_norm2.6.bias": "bert.encoder.layer.13.output.LayerNorm.bias",
  "module.layer_norm2.7.weight": "bert.encoder.layer.15.output.LayerNorm.weight",
  "module.layer_norm2.7.bias": "bert.encoder.layer.15.output.LayerNorm.bias",
  "module.layer_norm2.8.weight": "bert.encoder.layer.17.output.LayerNorm.weight",
  "module.layer_norm2.8.bias": "bert.encoder.layer.17.output.LayerNorm.bias",
  "module.layer_norm2.9.weight": "bert.encoder.layer.19.output.LayerNorm.weight",
  "module.layer_norm2.9.bias": "bert.encoder.layer.19.output.LayerNorm.bias",
  "module.layer_norm2.10.weight": "bert.encoder.layer.21.output.LayerNorm.weight",
  "module.layer_norm2.10.bias": "bert.encoder.layer.21.output.LayerNorm.bias",
  "module.layer_norm2.11.weight": "bert.encoder.layer.23.output.LayerNorm.weight",
  "module.layer_norm2.11.bias": "bert.encoder.layer.23.output.LayerNorm.bias",
  "module.pooled_layer.dense.weight": "bert.t_pooler.dense.weight",
  "module.pooled_layer.dense.bias": "bert.t_pooler.dense.bias"
}
//  "module.seq_relationship.weight": "cls.bi_seq_relationship.weight",
//  "module.seq_relationship.bias": "cls.bi_seq_relationship.bias",
//  "module.mrfr_dense.weight": "",
//  "module.mrfr_dense.bias": "",
//  "module.transformer_obj.dense.weight": "",
//  "module.transformer_obj.dense.bias": "",
//  "module.transformer_obj.LayerNorm.weight": "",
//  "module.transformer_obj.LayerNorm.bias": "",
//  "module.pred_layer.proj.weight": "",
//  "module.pred_layer.proj.bias": "",
//  "module.pred_obj_layer.proj.weight": "",
//  "module.pred_obj_layer.proj.bias": ""