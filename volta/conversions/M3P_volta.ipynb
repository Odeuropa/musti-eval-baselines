{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ckpt conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/science/image/nlp-datasets/emanuele/checkpoints/M3P/checkpoint.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'n_total_iter', 'best_metrics', 'best_stopping_criterion', 'model', 'model_optimizer', 'params'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ckpt['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ckpt\n",
    "old_keys = []\n",
    "new_keys = []\n",
    "for key in model.keys():\n",
    "    new_key = key.replace(\"module.\", \"bert.encoder.\")\n",
    "    old_keys.append(key)\n",
    "    new_keys.append(new_key)\n",
    "for old_key, new_key in zip(old_keys, new_keys):\n",
    "    model[new_key] = model.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/science/image/nlp-datasets/emanuele/checkpoints/iglue/conversions/pretrain/m3p_checkpoint_22.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "sys.path.append(\"../\")\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from volta.config import M3PConfig\n",
    "from volta.encoders import M3PForVLTasks\n",
    "\n",
    "# Create corresponding VOLTA model\n",
    "config_file = \"../config/m3p_base.json\"\n",
    "config = M3PConfig.from_json_file(config_file)\n",
    "\n",
    "tasks_config_file = \"../config_tasks/iglue_ku_trainval_tasks.yml\"\n",
    "with open(tasks_config_file, \"r\") as f:\n",
    "    task_cfg = edict(yaml.safe_load(f))\n",
    "task_id = '21'\n",
    "task = \"TASK\" + task_id\n",
    "\n",
    "ckpt_path = \"/science/image/nlp-datasets/emanuele/checkpoints/iglue/conversions/pretrain/m3p_checkpoint_22.bin\"\n",
    "model = M3PForVLTasks.from_pretrained(ckpt_path, config=config, task_cfg=task_cfg, task_ids=[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dump_path', 'exp_name', 'save_periodic', 'exp_id', 'fp16', 'encoder_only', 'english_only', 'emb_dim', 'n_layers', 'n_dec_layers', 'n_heads', 'dropout', 'attention_dropout', 'gelu_activation', 'share_inout_emb', 'sinusoidal_embeddings', 'attention_setting', 'asm', 'context_size', 'word_pred', 'sample_alpha', 'word_mask_keep_rand', 'word_shuffle', 'word_dropout', 'word_blank', 'word_mass', 'data_path', 'lgs', 'src_lgs', 'ag_lgs', 'lg_sampling_factor', 'vocab_path', 'input_fea_dir', 'google_path', 'sbu_path', 'coco_path', 'flicker_path', 'mild_path', 'slide_path', 'max_vocab', 'min_count', 'batch_size', 'seq_per_img', 'max_region_num', 'bptt', 'min_len', 'max_len', 'group_by_size', 'max_batch_size', 'tokens_per_batch', 'split_data', 'optimizer', 'clip_grad_norm', 'epoch_size', 'max_epoch', 'stopping_criterion', 'validation_metrics', 'lambda_mlm', 'lambda_clm', 'lambda_pc', 'lambda_mass', 'lambda_ic', 'lambda_imlm', 'lambda_ida', 'lambda_tifg', 'lambda_rel', 'lambda_mrm', 'lambda_mrfr', 'lambda_t2i', 'lambda_i2t', 'clm_steps', 'mlm_steps', 'mass_steps', 'mt_steps', 'ae_steps', 'bt_steps', 'pc_steps', 'cross_modal_steps', 'cross_mass_steps', 'cross_ae_steps', 'cross_gan_steps', 'cross_rel_steps', 'cross_mlm_steps', 'cross_mrm_steps', 'cross_mrfr_steps', 'text_steps', 'reload_model', 'reload_checkpoint', 'beam_size', 'length_penalty', 'early_stopping', 'eval_bleu', 'eval_only', 'debug_train', 'debug_pretrain', 'debug_slurm', 'local_rank', 'master_port', 'refine_image', 'refine_layers', 'refine_encoder', 'use_noise', 'accumulate_gradients', 'amp', 'use_memory', 'is_cross_modal', 'is_understanding', 'is_generation', 'is_pretrain', 'use_externel_att', 'use_enc_att', 'save_every_epoch', 'multi_reload_model', 'bin_cls_loss_weight', 'multi_cls_loss_weight', 'sent_ratio', 'word_ratio', 'sample_n', 't2i_flag', 'i2t_flag', 'coco_method', 'eval_n', 'eval_images', 'retrieval_batch', 'retrieval_workers', 'test_splits', 'use_new_fea', 'eval_path', 'google_valid_path', 'train_order_path', 'cross_lingual_path', 'num_workers', 'ft_lgs', 'is_latent', 'kld_alpha', 'rec_alpha', 'is_mild', 'qp_type', 'ft_all', 'is_mt', 'mt_only_text', 'is_ntg', 'is_slide', 'is_freelb', 'free_text', 'free_img', 'langs', 'id2lang', 'lang2id', 'n_langs', 'mono_dataset', 'para_dataset', 'eos_index', 'pad_index', 'mask_index', 'n_words', 'word_mask', 'word_keep', 'word_rand', 'is_slurm_job', 'global_rank', 'world_size', 'n_gpu_per_node', 'n_nodes', 'node_id', 'is_master', 'multi_node', 'multi_gpu', 'command', 'pred_probs', 'lambda_mlm_config', 'lambda_mass_config', 'lambda_ic_config', 'lambda_imlm_config', 'lambda_ida_config', 'lambda_tifg_config', 'lambda_rel_config', 'lambda_mrm_config', 'lambda_mrfr_config', 'lambda_t2i_config', 'lambda_i2t_config'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ckpt['params']\n",
    "params.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
